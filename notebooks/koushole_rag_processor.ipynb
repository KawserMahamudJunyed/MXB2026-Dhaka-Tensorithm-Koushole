{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üöÄ Koushole RAG Processor\n",
                "\n",
                "**Process NCTB textbooks for RAG using FREE cloud GPU**\n",
                "\n",
                "This notebook uses:\n",
                "- **Surya OCR v0.17+** (best accuracy for Bangla)\n",
                "- **Voyage AI** (50M free embedding tokens)\n",
                "- **Supabase** (cloud storage)\n",
                "\n",
                "---\n",
                "\n",
                "**SETUP:**\n",
                "1. Go to Runtime ‚Üí Change runtime type ‚Üí Select **T4 GPU**\n",
                "2. Run all cells in order\n",
                "3. Enter your API keys when prompted"
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "#@title 1Ô∏è‚É£ Install Dependencies (takes ~3 minutes)\n",
                "!pip install -q surya-ocr pdf2image Pillow supabase voyageai\n",
                "!apt-get install -q poppler-utils\n",
                "print(\"‚úÖ Dependencies installed!\")"
            ],
            "metadata": {
                "id": "install"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title 2Ô∏è‚É£ Enter Your API Keys\n",
                "from getpass import getpass\n",
                "\n",
                "SUPABASE_URL = input(\"Enter Supabase URL: \")\n",
                "SUPABASE_KEY = getpass(\"Enter Supabase Service Key: \")\n",
                "VOYAGE_API_KEY = getpass(\"Enter Voyage AI API Key: \")\n",
                "\n",
                "print(\"‚úÖ Keys saved!\")"
            ],
            "metadata": {
                "id": "keys"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title 3Ô∏è‚É£ Initialize Clients\n",
                "from supabase import create_client\n",
                "import voyageai\n",
                "\n",
                "supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
                "voyage = voyageai.Client(api_key=VOYAGE_API_KEY)\n",
                "\n",
                "print(\"‚úÖ Connected to Supabase and Voyage AI!\")"
            ],
            "metadata": {
                "id": "init"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title 4Ô∏è‚É£ Setup Surya OCR v0.17+\n",
                "from surya.detection import DetectionPredictor\n",
                "from surya.recognition import RecognitionPredictor\n",
                "\n",
                "print(\"Loading Surya OCR models...\")\n",
                "det_predictor = DetectionPredictor()\n",
                "rec_predictor = RecognitionPredictor(det_predictor)\n",
                "print(\"‚úÖ Surya OCR ready!\")"
            ],
            "metadata": {
                "id": "surya_setup"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title 5Ô∏è‚É£ Helper Functions\n",
                "from pdf2image import convert_from_bytes\n",
                "import requests\n",
                "from tqdm import tqdm\n",
                "from PIL import Image\n",
                "\n",
                "def extract_text_surya(pdf_bytes):\n",
                "    \"\"\"Extract text from PDF using Surya OCR v0.17+\"\"\"\n",
                "    images = convert_from_bytes(pdf_bytes, dpi=150)\n",
                "    \n",
                "    all_text = []\n",
                "    batch_size = 5\n",
                "    \n",
                "    for i in tqdm(range(0, len(images), batch_size), desc=\"OCR Progress\"):\n",
                "        batch = images[i:i+batch_size]\n",
                "        \n",
                "        # Run recognition (detection is handled internally)\n",
                "        rec_results = rec_predictor(batch, langs=[\"bn\", \"en\"])\n",
                "        \n",
                "        for page_result in rec_results:\n",
                "            page_text = \"\\n\".join([line.text for line in page_result.text_lines])\n",
                "            all_text.append(page_text)\n",
                "    \n",
                "    return \"\\n\\n\".join(all_text)\n",
                "\n",
                "def chunk_text(text, chunk_size=2000, overlap=200):\n",
                "    \"\"\"Split text into overlapping chunks\"\"\"\n",
                "    chunks = []\n",
                "    start = 0\n",
                "    while start < len(text):\n",
                "        end = start + chunk_size\n",
                "        chunk = text[start:end]\n",
                "        if chunk.strip():\n",
                "            chunks.append(chunk.strip())\n",
                "        start = end - overlap\n",
                "        if start >= len(text) - overlap:\n",
                "            break\n",
                "    return [c for c in chunks if len(c) > 50]\n",
                "\n",
                "def generate_embeddings(chunks):\n",
                "    \"\"\"Generate embeddings using Voyage AI\"\"\"\n",
                "    embeddings = []\n",
                "    batch_size = 20\n",
                "    \n",
                "    for i in tqdm(range(0, len(chunks), batch_size), desc=\"Embedding\"):\n",
                "        batch = chunks[i:i+batch_size]\n",
                "        batch = [c[:8000] for c in batch]\n",
                "        \n",
                "        result = voyage.embed(\n",
                "            texts=batch,\n",
                "            model=\"voyage-multilingual-2\",\n",
                "            input_type=\"document\"\n",
                "        )\n",
                "        embeddings.extend(result.embeddings)\n",
                "    \n",
                "    return embeddings\n",
                "\n",
                "print(\"‚úÖ Helper functions ready!\")"
            ],
            "metadata": {
                "id": "helpers"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title 6Ô∏è‚É£ Fetch Books Without Embeddings\n",
                "\n",
                "# Get library books\n",
                "library_result = supabase.table('library_books').select('id, title, file_url').or_('chunks_generated.is.null,chunks_generated.eq.false').execute()\n",
                "library_books = library_result.data or []\n",
                "\n",
                "# Get official resources\n",
                "official_result = supabase.table('official_resources').select('id, title, file_url').or_('chunks_generated.is.null,chunks_generated.eq.false').execute()\n",
                "official_books = official_result.data or []\n",
                "\n",
                "print(f\"üìö Found {len(library_books)} library books\")\n",
                "print(f\"üìñ Found {len(official_books)} official books\")\n",
                "print(f\"üìä Total: {len(library_books) + len(official_books)} books to process\")"
            ],
            "metadata": {
                "id": "fetch_books"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title 7Ô∏è‚É£ Process All Books üöÄ\n",
                "import time\n",
                "\n",
                "def process_book(book, source_type):\n",
                "    title = book['title']\n",
                "    print(f\"\\nüìö Processing: {title}\")\n",
                "    \n",
                "    try:\n",
                "        print(\"  üì• Downloading...\")\n",
                "        response = requests.get(book['file_url'])\n",
                "        if response.status_code != 200:\n",
                "            print(f\"  ‚ùå Download failed\")\n",
                "            return False\n",
                "        \n",
                "        pdf_bytes = response.content\n",
                "        print(f\"  üìÑ Size: {len(pdf_bytes) / 1024 / 1024:.2f} MB\")\n",
                "        \n",
                "        print(\"  üîÆ Running Surya OCR...\")\n",
                "        text = extract_text_surya(pdf_bytes)\n",
                "        print(f\"  ‚úÖ Extracted {len(text)} characters\")\n",
                "        \n",
                "        if len(text) < 200:\n",
                "            print(\"  ‚ùå Not enough text\")\n",
                "            return False\n",
                "        \n",
                "        chunks = chunk_text(text)\n",
                "        print(f\"  üì¶ Created {len(chunks)} chunks\")\n",
                "        \n",
                "        print(\"  üî¢ Generating embeddings...\")\n",
                "        embeddings = generate_embeddings(chunks)\n",
                "        print(f\"  ‚úÖ Generated {len(embeddings)} embeddings\")\n",
                "        \n",
                "        print(\"  üíæ Storing in database...\")\n",
                "        id_column = 'library_book_id' if source_type == 'library' else 'resource_id'\n",
                "        \n",
                "        supabase.table('book_chunks').delete().eq(id_column, book['id']).execute()\n",
                "        \n",
                "        for i in range(0, len(chunks), 50):\n",
                "            batch = []\n",
                "            for j in range(i, min(i + 50, len(chunks))):\n",
                "                batch.append({\n",
                "                    id_column: book['id'],\n",
                "                    'chunk_index': j,\n",
                "                    'chunk_text': chunks[j],\n",
                "                    'embedding': embeddings[j]\n",
                "                })\n",
                "            supabase.table('book_chunks').insert(batch).execute()\n",
                "        \n",
                "        table = 'library_books' if source_type == 'library' else 'official_resources'\n",
                "        supabase.table(table).update({\n",
                "            'chunks_generated': True,\n",
                "            'total_chunks': len(chunks),\n",
                "            'is_processed': True\n",
                "        }).eq('id', book['id']).execute()\n",
                "        \n",
                "        print(f\"  ‚úÖ DONE: {len(chunks)} chunks stored!\")\n",
                "        return True\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"  ‚ùå Error: {e}\")\n",
                "        return False\n",
                "\n",
                "success = 0\n",
                "failed = 0\n",
                "\n",
                "for book in library_books:\n",
                "    if process_book(book, 'library'):\n",
                "        success += 1\n",
                "    else:\n",
                "        failed += 1\n",
                "    time.sleep(2)\n",
                "\n",
                "for book in official_books:\n",
                "    if process_book(book, 'official'):\n",
                "        success += 1\n",
                "    else:\n",
                "        failed += 1\n",
                "    time.sleep(2)\n",
                "\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(f\"üèÅ PROCESSING COMPLETE!\")\n",
                "print(f\"‚úÖ Success: {success}\")\n",
                "print(f\"‚ùå Failed: {failed}\")"
            ],
            "metadata": {
                "id": "process_all"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "\n",
                "## ‚úÖ All Done!\n",
                "\n",
                "Your books are now processed and stored in Supabase.\n",
                "\n",
                "**Next steps:**\n",
                "1. Test RAG chat on your website\n",
                "2. Come back weekly to process new uploads"
            ],
            "metadata": {
                "id": "done"
            }
        }
    ]
}